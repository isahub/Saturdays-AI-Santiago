{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3.0 Regresión Logística\n",
    "\n",
    "\n",
    "1. Recordemos que el objetivo de un método de _clasificación_ es asignar una clase o categoría a una observación.\n",
    "2. Regresión logística es uno de los métodos que podemos usar para esto y es también el método más famoso y usado.\n",
    "3. *Es* una regresión, pero no dejes que esto te confunda. Estima probabilidades de pertenencia a clases.\n",
    "4. Este notebook complementa el modulo de Regresión Logística al ilustrar la aplicación en código de lo explicado en clase.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Notebook'></a>\n",
    "### Estructura del Notebook\n",
    "- [Importando paquetes](#imporp)\n",
    "- [Leyendo el dataset](#rds)\n",
    "    - [Valores faltantes](#msvl)\n",
    "     \n",
    "- [Implementación de Regresión Logística](#implementation)\n",
    "    - [Admisiones](#addmission)\n",
    "    - [Republicano o Demócrata](#repdemoc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='imporp'></a>\n",
    "## Importando paquetes\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## paquetes básicos\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "## paquetes para graficar\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "## paquetes Scikit learn y Statsmodel\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "import statsmodels.api as sm\n",
    "\n",
    "## Funcionalidades del sistema operativo\n",
    "import os\n",
    "\n",
    "!pip install watermark\n",
    "## Lineas de código necesarias para asegurarse de que los gráficos aparezcan en el notebook, y chequeo de las versiones de los paquetes.\n",
    "%matplotlib inline\n",
    "%load_ext watermark\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%watermark -v -d -a 'Delta Analytics' -p scikit-learn,matplotlib,numpy,pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='rds'></a>\n",
    "## Leyendo el dataset\n",
    "---\n",
    "1. En este ejercicio estamos usando el dataset de admisiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = os.path.join('../data', '')\n",
    "admission_filepath = os.path.join(data_directory, 'Admissions.csv')\n",
    "admissions = pd.read_csv(admission_filepath)\n",
    "admissions.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "admissions.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='msvl'></a>\n",
    "### Valores faltantes\n",
    "---\n",
    "1. De haber, botarlos (no la mejor práctica, pero esta bien por ahora)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "admissions.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "admissions.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "admissions.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "admissions.prestige.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='implementation'></a>\n",
    "## Implementación de Regresión Logística\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='addmission'></a>\n",
    "### Admisiones\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Obten estadísticas básicas de tu dataset\n",
    "admissions.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## dejemos nuestra columna prestige como enteros\n",
    "admissions['prestige'] = admissions['prestige'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "admissions.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Si exploras prestige verás que es una variable categórica, la cual puedes convertir a one hot enconding => pandas tiene una función lista para esto\n",
    "##### https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html\n",
    "\n",
    "### Unos puntos de precaución:\n",
    "1. Una vez creado el one hot encoding tenemos que botar la columna original (prestige).\n",
    "2. Tenemos que botar una de las nuevas columnas\n",
    "3. Los pasos anteriores son necesarios para evitar dependencias lineales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_dummies = pd.get_dummies(admissions.prestige, prefix=\"prestige\", drop_first=True)\n",
    "get_dummies.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Agreguemos estas nuevas columnas a nuestro dataset usando concatenación y agreguemos el intercepto\n",
    "df = pd.concat([admissions, get_dummies], axis=1)\n",
    "df.drop(['prestige'], inplace=True, axis=1)\n",
    "df['intercept'] = 1.0\n",
    "\n",
    "## tenemos ahora un dataset listo para ser analizado\n",
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Define X e y '''\n",
    "y = df['admit'] \n",
    "columns_ = df.columns.tolist()\n",
    "exclude_col = ['admit']\n",
    "X = df[[i for i in columns_ if i not in exclude_col]]\n",
    "print (X.shape, y.shape)\n",
    "\n",
    "''' divide los datos'''\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=10)\n",
    "\n",
    "print (X_train.shape, y_train.shape)\n",
    "print (X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## construye y ajusta la regresión\n",
    "logit = sm.Logit(y_train, X_train)\n",
    "logit_result = logit.fit()\n",
    "## Imprimamos los resultados\n",
    "print (logit_result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Coeficientes\")\n",
    "print(logit_result.params)\n",
    "print (\"\\n\")\n",
    "print(\"Valores p\")\n",
    "print(logit_result.pvalues)\n",
    "print (\"\\n\")\n",
    "print(\"Variables dependientes\")\n",
    "print(logit.endog_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretando los coeficientes de la regresión logística.\n",
    "### Recuerdas el cociente de probabilidad?\n",
    "En este caso, el uso del cociente de probabilidad nos ayudará a entender como una unidad de incremento o disminución de cualquiera de las variables afecta la probabilidad de admisión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (np.exp(logit_result.params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Vemos que la probabilidad de admisión podría decrecer en un 46% si el prestigio de la escuela es 2, o en un 23% si el prestigio de la escuela es 3. Estos valores son de nuestro set de entrenamiento, veamos ahora nuestro set de test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediciendo y Evaluando\n",
    "Si llamamos el método de predicción, obtendremos las probabilidades predictivas. Pero para hacer una predicción de si el estudiante será admitido o no, debemos convertir estas probabilidades a las etiquetas 1=admitido o 0=no admitido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## He aquí las probabilidades predichas\n",
    "predictions = logit_result.predict(X_test)\n",
    "print (predictions[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(predictions);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_nominal = [ 0 if x < 0.5 else 1 for x in predictions]\n",
    "print (predictions_nominal.count(0))\n",
    "print (predictions_nominal.count(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de confusión y reporte de clasificación\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "confmat = confusion_matrix(y_true=y_test, y_pred=predictions_nominal)\n",
    "confusion = pd.DataFrame(confmat, index=['True_Label_0 Rejected', 'True_Label_1 Admitted'],\n",
    "                         columns=['Predict_Label_0 Rejected', 'Predict_Label_1 Admitted'])\n",
    "\n",
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (classification_report(y_test, predictions_nominal, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementemos la misma regresión logística usando scikit learn\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Baseline'''\n",
    "'''Recuerda 0 es no admitido 1 es admitido'''\n",
    "print (df['admit'].value_counts(), \"\\n\" )\n",
    "print (\"Si escojemos al azar, %.0f porciento del tiempo escojeremos admitido. \" \n",
    "        % ((np.mean(df['admit']))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic = LogisticRegression()\n",
    "logistic.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=logistic.predict(X_test)\n",
    "confmat = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "confusion = pd.DataFrame(confmat, index=['True_Label_0 Rejected', 'True_Label_1 Admitted'],\n",
    "                         columns=['Predict_Label_0 Rejected', 'Predict_Label_1 Admitted'])\n",
    "\n",
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (classification_report(y_test, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='repdemoc'></a>\n",
    "### Republicano o Demócrata\n",
    "---\n",
    "Para este ejercicio vamos a usar datos de [1984 United States Congressional Voting Records Database] [1]\n",
    "(echale una mirada al diccionario de los datos) para predecir si un congresista es republicano o demócrata.\n",
    "[1]: http://archive.ics.uci.edu/ml/machine-learning-databases/voting-records/house-votes-84.names \"1984 United States Congressional Voting Records Database\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define los nombres de las columnas/variables/características\n",
    "columns = [\n",
    "    \"class\", \n",
    "    \"handicapped_infants\", \n",
    "    \"water_project_cost\", \n",
    "    \"adoption_of_the_budget_resolution\", \n",
    "    \"physician_fee_freeze\",\n",
    "    \"el_salvador_aid\",\n",
    "    \"religious_groups_in_schools\",\n",
    "    \"anti_satellite_test_ban\",\n",
    "    \"aid_to_nicaraguan_contras\",\n",
    "    \"mx_missile\",\n",
    "    \"immigration\",\n",
    "    \"synfuels_corporation_cutback\",\n",
    "    \"education_spending\",\n",
    "    \"superfund_right_to_sue\",\n",
    "    \"crime\",\n",
    "    \"duty_free_exports\",\n",
    "    \"export_administration_act_south_africa\"\n",
    "]\n",
    "\n",
    "\n",
    "'''Vamos a leer los datos directamente de la web'''\n",
    "csv_url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/voting-records/house-votes-84.data\"\n",
    "\n",
    "''' Aquí leemos los datos y creamos una variable binaria 0 para Republicano 1 para Demócrata'''\n",
    "house_df = pd.read_csv(csv_url, names = columns)\n",
    "\n",
    "house_df['class'] = house_df['class'].map(lambda value: 0 if value == \"republican\" else 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Limpiemos el dataset\n",
    "house_df.replace('?', np.nan, inplace=True)\n",
    "house_df.ffill(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creemos las variables one hot encoded\n",
    "df_dummies = pd.get_dummies(house_df)\n",
    "df_dummies.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Define X e y '''\n",
    "y = df_dummies['class'] \n",
    "columns_ = df_dummies.columns.tolist()\n",
    "exclude_col = ['class']\n",
    "\n",
    "X = df_dummies[[i for i in columns_ if i not in exclude_col]]\n",
    "print (X.shape, y.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=10)\n",
    "print (X_train.shape, y_train.shape)\n",
    "print (X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Usa scikit learn'''\n",
    "r_d_logistic = LogisticRegression()\n",
    "r_d_logistic.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Baseline'''\n",
    "'''Recuerda  0 es republicana 1 es democrata'''\n",
    "print (df_dummies['class'].value_counts(), \"\\n\" )\n",
    "print (\"Si escojemos al azar, %.0f porciento del tiempo elijiremos demócrata\" \n",
    "        % ((np.mean(df_dummies['class']))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## prediciendo\n",
    "y_pred=r_d_logistic.predict(X_test)\n",
    "\n",
    "confmat = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "confusion = pd.DataFrame(confmat, index=['True_Label_0 Republican', 'True_Label_1 Democrat'],\n",
    "                         columns=['Predict_Label_0 Republican', 'Predict_Label_1 Democrat'])\n",
    "\n",
    "confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtengamos VP, FP, VN, FN de la matriz de confusión\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = confusion.loc['True_Label_0 Republican', 'Predict_Label_0 Republican']  \n",
    "\n",
    "FP = confusion.loc['True_Label_1 Democrat', 'Predict_Label_0 Republican']\n",
    "\n",
    "TN = confusion.loc['True_Label_1 Democrat', 'Predict_Label_1 Democrat']\n",
    "\n",
    "FN = confusion.loc['True_Label_0 Republican', 'Predict_Label_1 Democrat']\n",
    "\n",
    "values = sorted(zip(['True Positives','False Positives','True Negatives','False Negatives'], [TP, FP, TN, FN]))\n",
    "values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcula exactitud, Razón de error, Precisión,  y Recall\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Exactitud\n",
    "## Que tan seguido el clasificador está en lo correcto?\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print (\"Accuracy score: %.3f\" %(acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Razón de error \n",
    "## Que tan seguido el clasificador se equivoca?\n",
    "print (\"Error rate: %.3f\" % (((FP + FN))/ float(len(y_test))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Precisión\n",
    "## La habilidad del clasificador de evitar etiquetar una clase como miembro de otra\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "pcs = precision_score(y_test, y_pred)\n",
    "print (\"Precision: %.3f\" %(pcs*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Recall\n",
    "## Recall la habilidad del clasificador de identificar correctamente la clase actual\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "rcs = recall_score(y_test, y_pred)\n",
    "print (\"Recall: %.3f\" % (rcs*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (classification_report(y_test, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC and AUC\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Obten las probabilidades predichas en el set de test\n",
    "y_pp = r_d_logistic.predict_proba(X_test)[:,1]\n",
    "\n",
    "# roc_curve devuelve la razón de falsos positivos y verdaderos positivos a medida que el umbral cambia.\n",
    "# toma como argumentos y y las probabilidades predichas en la clase positiva.\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pp)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=[9,9])\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc, linewidth=10, color='g')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', linewidth=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=16)\n",
    "plt.ylabel('True Positive Rate', fontsize=16)\n",
    "plt.title('Receiver operating characteristic curve', fontsize=20)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
