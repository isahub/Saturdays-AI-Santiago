{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Naive Bayes\n\nNaive Bayes se refiere al uso del teorema de Bayes con suposiciones ingenuas sobre la independencia entre variables.\n\nLos clasificadores de Naive Bayes son populares en la categorización de texto. El objetivo de este modulo es aprender lo básico de Naive Bayes. Este módulo está dividido en las siguientes secciones:\n\n+ Preparación de los datos para el análisis\n+ Introducción a Naive Bayes\n+ Tokenización\n+ Vectorización\n+ Predicción\n+ Evaluación\n\nEste módulo coincide con nuestra clase de procesamiento de lenguaje natural con Naive Bayes."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Sin embargo, antes de ir a la sección uno sobre preparación de datos, comenzaremos por una revisión de los datos que estamos usando. Para la comprención de la metodología, nosotros:\n\n1. Primero, bajamos data de Twitter sobre microfinanza usando tweepy, una librería API de Twitter.\n2. Luego, clasificamos los comentarios de acuerdo a polaridad para asi obtener data de entrenamiento para nuestro modelo.\n    + Normalmente este proceso requriría clasificar manualmente ~20% de nuestros datos.\n    + En nuestro ejercisio, usamos un simple algoritmo llamado TextBlob para etiquetar todo el dataset.\n3. Después revisamos y corregimos manualmente las clasificaciones. \n    + (Nota, si estas interesada en ver el código usado para implementar esto, ve el archivo \"twitter_web_scraping.\")"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import pandas as pd\nimport seaborn as sns\nimport numpy as np\nimport string\n\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem.wordnet import WordNetLemmatizer\nfrom nltk.tokenize import TweetTokenizer\nfrom sklearn.model_selection import train_test_split\nimport re\nimport itertools\nfrom sklearn.feature_extraction.text import CountVectorizer\n\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.naive_bayes import MultinomialNB\n!pip install wordcloud\nfrom wordcloud import WordCloud\n\nimport matplotlib.pyplot as plt\n%matplotlib inline ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "path = '../data/'\nfilename = 'microfinance_tweets.csv'\ntry:\n    data = pd.read_csv(path+filename, encoding='ISO-8859-1')\nexcept FileNotFoundError:\n    import os\n    os.system(f'!git clone https://github.com/DeltaAnalytics/machine_learning_for_good_data {path}')\n    data = pd.read_csv(\"machine_learning_for_good_data/microfinance_tweets.csv\", encoding=\"ISO-8859-1\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#revisa los datos para ver que todo salió bien\ndata.head(10)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "La data de Twitter contiene 6 columnas:\n+ Comentarios: El post de Tweet que mencionó microfinanzas\n+ Fecha: La fecha del Tweet\n+ Favoritos: Número de favoritos\n+ Usuario: Nombre del autor del tweet\n+ Polaridad: la polaridad, que representa la positividad o negatividad del comentario de acuerdo a TextBlob\n+ Sentimiento: conversión de polaridad a positivo, negativo y neutro.\n\nNotar que este ejercisio simula realisticamente lo que pasaría en el mundo real. Nuestra data es limitada, y el proceso para obtener data de entrenamiento y test de calidad es dificil. Para entender nuestra data, haremos unos pocos ejercisios abajo. "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "## Cual es la distribución de sentimiento?\nsns.countplot(x = 'Sentiment', data = data)\ndata['Sentiment'].value_counts()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Parece que la mayoriá tiene comentarios positivos o neutros sobre microfinanza. De hecho, el volumen de comentarios negativos es lo más interesante y requiere mayor investigación."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "## Que són estos comentarios negativos?\n#formatea las columnas para que los comentarios no se corten\npd.set_option('display.max_columns', None) \npd.set_option('max_colwidth', 800)\n\n#muestra comentarios negativos\npd.DataFrame(data.loc[data['Sentiment'] == 'negative']['Comments'].unique()[0:10])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Pareciera que alguno de los comentarios negativos no son válidos y debiesen ser clasificados como neutrales. Sin embargo, alguno de los comentarios negativos son válidos, e.g., notificación de página falsa y actividad ilegal.\n\nAunque hay mucho más que podríamos investigar sobre los datos, continuaremos con la preparación de los datos para el modelo."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Prepara los datos para el modelo\n\nEl modo mas común de aplicar algoritmos de machine learning, como Naive Bayes, a anáisis de texto es convertir nuestro texto en características numéricas que el algorítmo puede entender.\n\nLa representación que crearemos es la **Bolsa de palabras**. Para pasar de nuestros datos, que actualmente están estructurados como una serie de strings, a una Bolsa de Palabras, **vectorizaremos** nuestros tweets.\n\nEsta **vectorización** de nuestros documentos de texto requerirá unos pocos pasos claves, que describiremos en más detalle en el [Módulo 8](https://docs.google.com/presentation/d/1vaxDuUROgaqix9Mfkyb4_h0cGkGwN7AUeLU1ozhtJW8/edit#slide=id.g227403103b_0_1171):\n\nPaso 0. Divide la data en sets de entrenamiento y test (esto no es parte de la vectorización) <br>\nPaso 1. Limpia y **tokeniza** el texto <br>\nPaso 2. Cuenta el número de palabras en cada texto\n\n#### Paso 0: Crea datos de entrenamiento y test\nEste paso debiese venir de forma natural. \nHemos clasificado sentimientos para todos nuestros datos, y escogemos una division 80-20 de entrenamiento-test, con observaciones asignadas al azar."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# A) Crea un set de test (20% de los datos) y entrenamiento (80% de los datos) \ntrain, test = train_test_split(data, test_size=0.2, random_state=42)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Verifica el largo de los set de test y entrenamiento para confirmar que los datos se dividieron en la proporción adecuada\nprint(len(train), len(test))\nprint(\"Split of {:.2%} train, {:.2%} test\".format(len(train)/len(data), len(test)/len(data)))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Paso 1: Limpia y tokeniza el texto\n\nComo mencionado, el modo más común de extrar vectores numéricos del texto es tener un set de **tokens** para los cuales tenemos conteos.\n\n**Tokenización** significa convertir un documento/sentencia/tweet en *tokens* individuales, que usualmente son palabras, o unidades 'como' palabras.\n\nCuando creamos estos tokens 'como' palabras, queremos estandarizarlos de modo que palabras similares estén agrupadas. Esto hace los tokens más útiles que palabras sin procesar. Mira el [NLP Modulo](https://docs.google.com/presentation/d/1vaxDuUROgaqix9Mfkyb4_h0cGkGwN7AUeLU1ozhtJW8/edit#slide=id.g227403103b_0_1050) para más detalles!\n\nCreamos una función para lemalizar** estas palabras. Afortunádamente, NLTK tiene diferentes librerias que simplifican esta tarea.\n\nAquí usamos el tokenizador de NLTK para lidiar con un tweet con hashtags y smileys."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "## From http://www.nltk.org/api/nltk.tokenize.html\ntweet_tokenizer = TweetTokenizer()\nexample_tweet = \"This is a cooool #dummysmiley: :-) :-P <3 and some arrows < > -> <--\"\ntweet_tokenizer.tokenize(example_tweet)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Nota: El tokenizador de tweet tiene la capacidad adicional de reducir el largo de algunas palabras laaaargas."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Paso 2) Cueta el número de palabras en cada 'documento'\n\nEste es el paso que trae nuestro texto a la representación *Bolsa de Palabras*.\n\nUna bolsa de palabras nos permite trabajar con text libre de forma estructurada. Usamos un simple conteo para nuestra bolsa de palabras, pero las librerias TF-IDF sklearn libraries también están disponibles y pueden ser utilizadas en otros problemas de NLP.\n\nUsamos la función **CountVectorization** de la libreria sklearn\nThe TF-IDF Vectorizer is available by using:\n\n`from sklearn.feature_extraction.text import TfidfVectorizer`\n\nNotar la diferencia en el uso de las funciones para ajustar la bolsa de palabras de test vs la de entrenamiento."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# C) Representa el texto en una bolsa de palabras por medio de CountVectorization en la libreria sklearn.\nvectorizer = CountVectorizer(tokenizer=tweet_tokenizer.tokenize)\ntrain_features = vectorizer.fit_transform(train['Comments'])\ntest_features =  vectorizer.transform(test['Comments'])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "vectorizer.get_feature_names()[0:20]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Estas son nuestras *características*, i.e., todos los tokens limpios de todos nuestros tweets. Un tweet de entrenamiento o de test puede ser representado ahora como un conteo de cuantas veces esta característica aparece. "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Prueba el vectorizador mirando el tamaño de los vectores y extractos\nprint('Length of Vectorizer Vocabulary: ', len(vectorizer.vocabulary_))\nprint('Shape of Sparse Matrix: ', test_features.shape)\nprint('Amount of Non-Zero occurrences: ', test_features.nnz)\n\n# Porcentajes de valores distintos de zero\ndensity = 100.0 * (test_features.nnz / (test_features.shape[0] * test_features.shape[1]))\nprint('Density: {}'.format((density)))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Tenemos 6184 *tokens* en nuestro cuerpo. La matriz de características del set de test es una representación de cada unos de los 649 tweets como un vector del conteo de tokens."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Para entender como el vectorizador guarda palabras, pondremos como input un ejemplo del test\nsample_test = test['Comments'].iloc[11]\nprint(\"Sample comment: \", sample_test, \"\\n\")\nsample_vector = vectorizer.transform([sample_test])\nprint(\"Vectorization:\")\nprint(sample_vector)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Esto significa que tenemos un conteo de palabras para palabras en estos índices.\n# Podemos usar get_feature_names() en el vectorizador para ver cuales son estas palabras\nprint(list(vectorizer.get_feature_names()[i] for i in sample_vector.indices))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Miremos a una nube de palabras de nuestros datos para ver que palabras son las más comunes!"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#cloud = WordCloud(width=1600, height=1200).generate(\" \".join(data['Comments'].astype(str)))\ncloud = WordCloud(width=1600, height=1200).generate(\" \".join(vectorizer.get_feature_names()))\nplt.figure(figsize=(20, 15))\nplt.imshow(cloud)\nplt.axis('off')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Estas palabras tienen sentido dado nuestro foco. Tenemos también algunas urls (https, co)."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Introducción a Naive Bayes\nComenzaremos corriendo Naive Bayes en el texto y verificando que tan bien predice las clasificaciones. Este paso es muy simple ya que ya hemos preparado nuestra data en el formato de bolsa de palabras. <br>"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#entrena tu data usando multinomial NB de la librería sklearn\nnb = MultinomialNB()\nnb.fit(train_features, train['Sentiment'])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#prueba con set de prueba\npreds = nb.predict(test_features)\n\n#imprime la precisión de tu modelo\naccuracy = (preds == test['Sentiment'])\n'Accuracy : {:.2%}'.format(accuracy.sum() / len(accuracy))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "La precisión es alta ~86%. La mayoría de los análisis de sentimiento tienen una precisión de ~80% cuando has ajustado el modelo en un test de entrenamiento real. En este caso, la precisión de 86% está probáblemente inflada porque hemos usado TextBlob para determinar el sentimiento correcto en nuestro set de entrenamiento. \n\nNuestra medida actual de precisión es un valor uni-dimensional. No sabemos en que nos estamos equivocando cuando clasificamos los sentimientos mal. Una herramienta para entender mejor como estamos clasificando es la matriz de confución (primero introducida en la clase de regreción logística.)"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "## Se puede tomar como dada de la documentación de la matriz de confución en skalearn\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    Esta función imprime y grafica la matriz de confución.\n    Nomalización se aplica al configurar `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "class_names = set(data['Sentiment'])\ncnf_matrix = confusion_matrix(test['Sentiment'], preds)\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=class_names,\n                      title='Confusion matrix, basic NB')\n\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n                      title='Normalized confusion matrix')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Los resultados de arriba muestran que estamos comunmente prediciendo comentarios positivos como neutrales. Esta mal clasificación no es tan preocupante como nuestra segunda mal clasificación mas común de clasificar comentarios negativos como positivos."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Conclusión\n\nHemos revisado lo básico de Naive Bayes e investigado como mejoras pueden ser usadas en el caso de análisis de sentimiento. \n\nHay muchos tipos de pequeñas mejoras que puedes aplicar a un modelo de Naive Bayes, y sualmente depende del tipo de dato. Por ejemplo, si sabes que el texto a usar es particularmente informal, sería bueno adaptar tu función analizadora para lidiar con estas informalidades. Si el texto no es informal, este cambio no cambiará mucho la precisión de tu modelo. Para más detalles de como mejoras pueden ser aplicadas a Naive bayes, mira el laboratorio \"naive_bayes_detail\""
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Sources: https://medium.com/tensorist/classifying-yelp-reviews-using-nltk-and-scikit-learn-c58e71e962d9, https://www.dataquest.io/blog/naive-bayes-tutorial/, http://nlpforhackers.io/sentiment-analysis-intro/, http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html <br>"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}