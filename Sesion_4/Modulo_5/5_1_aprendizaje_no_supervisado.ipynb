{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Introducci√≥n al aprendizaje No supervisado"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Previamente, aprendimos a usar regresiones lineales para estudiar si ciertas caracteristicas son utiles para predecir el resultado observado. Luego, hemos usado metodos de ensamble para refinar nuestras predicciones.\n\nEn este notebook, pasaremos de la predicci√≥n a encontrar patrones.\n"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Qu√© haremos en este notebook:\n-----\n\n1. Entregar una introducci√≥n general al aprendizaje no supervisado.\n1. Usar agrupamiento k-means como tecnica de aprendizaje no supervisado.\n1. Cargar y explorar un set de datos.\n1. Encontrar grupos mediante algoritmos k-means.\n1. Evaluar nuestro resultado con el m√©todo Elbow.\n1. Visualizar los datos con PCA. "
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Aprendizaje no supervisado: B√∫squeda de patrones en los datos. üîç\n------\n\nEl Aprendizaje no supervisado es el proceso mediante el cual identificamos patrones en el conjunto de datos. A menudo, identificar patrones es un paso inicial para entender nuestro datos. Los m√©todos de Aprendizaje no supervisado con una serie de t√©cnicas dise√±adas para _explorar_ y encontrar \"estructuras escondidas\" m√°s que predecir resultados.\n\nEl aprendizaje no supervisado no necesita datos etiquetados, por lo tanto puede trabajar en un rango m√°s amplio de datos. De hecho, la mayor parte de los datos del mundo no est√°n etiquetados. Sin embargo, ya que no hay etiquetas / respuestas correctas no siempre hay una retroalimentaci√≥n clara para validar que los resultados son correctos.\n \nEl aprendizaje no supervisado tambi√©n se conoce como **Data Mining**."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "No supervisado\n------"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "2 Tipos de Aprendizaje no Supervisado\n--------\n\n1. Reducci√≥n de dimensi√≥n (Dimension Reduction)\n\n1. Agrupamiento (Clustering)"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Qu√© es la reducci√≥n de dimensi√≥n?\n------\n\nLa reducci√≥n de dimensi√≥n tiene como objetivo encontrar un menor n√∫mero de caracter√≠sticas que se utilizar√°n para construir un modelo que sea significativo. Hay muchas razones para reducir el numero de car√°cteristicas en un conjunto de datos, desde evitar el sobreajuste (overfitting) o acelerando el tiempo de modelado.\n\nUna de las t√©cnicas m√°s comunes para reducir dimensiones es el An√°lisis de Componentes Principales (Principal Component Analysis, PCA)."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Qu√© es el Agrupamiento?\n-----\n<br>\n<center><img src=\"./images/clustering.png\" width=\"700\"></center>\n\nEl agrupamiento (clustering), es tal como suena: juntar los datos en sub-grupos (clusters) basados en caracteristicas similares. Entonces, esos subgrupos son usados para el analisis posterior. El clustering es una forma intuitiva de entender los diversos segmentos naturales que conforman tu poblaci√≥n de datos y ayuda a facilitar la visualizaci√≥n de los datos.\n\nEl m√©todo Clustering tambi√©n es llamado [an√°lisis de grupos](https://es.wikipedia.org/wiki/An%C3%A1lisis_de_grupos), segmentaci√≥n de datos o paticionamiento de datos.\n\nNos enfocaremos en el clustering de datos en el resto de este notebook."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Introducci√≥n al agrupamiento usando K-means\n------\n\n<center><img src=\"./images/k_means.png\" width=\"700\"></center>\n\n\nK-means es una de las t√©cnicas de agrupamiento m√°s usadas. El objetivo del algoritmo K-means, es encontrar un conjunto de puntos cercanos entre si (un cluster) y que adem√°s est√©n lejos de otros puntos (otros clusters)."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "C√≥mo hacemos un agrupamiento usando k-means?\n-----\n\nInicialmente, los puntos est√°n <i> asignados al azar</i> a un cluster. Con esto, el centro de cada grupo es calculado.\n\nLuego se alterna entre dos pasos:\n\n1. Paso de asignaci√≥n: Las observaciones se asignan a un grupo donde el centro est√° m√°s cerca de ellos.\n\n2. Paso de actualizaci√≥n: Se determinan nuevos puntos centrales de los grupos.\n\nEl proceso se repite hasta que las observaciones barajadas se vuelven distantes a diferentes grupos y el centro de cada grupo no se mueve.\n\nEn otras palabras, las observaciones se reasignan constatemente a los grupos, hasta que se minimiza la distancia entre una observaci√≥n y el punto central m√°s cercano."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Ejemplo K-means\n-----\n\n![](../images/left.gif)"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "-----\nAjuste de K-means a los datos Kiva\n------\n\nAhora vamos a ajustar k-means a una <b>partici√≥n</b> o <b>segmento</b> de los datos Kiva en clusters.\n\nImportemos los paquetes m√°s importantes para comenzar el c√≥digo:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Data loading and manipulation\nimport pandas as pd\nimport numpy as np\n\n# K-Means clustering algorithm\nfrom sklearn.cluster import KMeans\n\n# Plotting\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Places the plots in the Jupyter Notebook\n%matplotlib inline\n\n# PCA dimension reduction\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\n\n# Keep everything visible\npd.set_option('display.max_columns', 80)\npd.set_option('expand_frame_repr', True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "----\nCargar y explorar los datos\n-----"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Load data that is saved locally\npath = '../data/'\nfilename = 'loans.csv'\ndf = pd.read_csv(path+filename)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Load data from Github if using colab\n#!git clone https://github.com/DeltaAnalytics/machine_learning_for_good_data\n#df = pd.read_csv(\"machine_learning_for_good_data/loans.csv\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Siempre es una buena idea üí° echar un vistazo a los datos sin procesar."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df.head(n=2)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(f\"Hay {df.shape[1]:,} columnas en el dataframe.\")\nprint(f\"Hay {df.shape[0]:,} filas en el dataframe.\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df.describe()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Ahora que \n\n\nAhora que tenemos nuestros datos configurados, podemos comenzar a dividir nuestros datos en cl√∫steres basados solo en algunas caracter√≠sticas. Pensemos c√≥mo elegir estos ...\n\nComo prestatario o prestamista potencial, ¬øqu√© ser√≠a interesante explorar?\n\nEn los notebooks anteriores, hemos explorado algunas ideas interesantes:\n\n- Cu√°nto dinero debe pedir prestado un prestatario\n- El tiempo que lleva financiar un pr√©stamo\n- Qu√© caracter√≠sticas pueden influir en el monto del pr√©stamo\n- Si dividimos a los prestatarios en grupos distintos seg√∫n la rapidez con la que pueden financiar un pr√©stamo, ¬øpodremos aprender algo sobre estos grupos de prestatarios?\n\nEl algoritmo k-means utiliza caracter√≠sticas num√©ricas de valor continuo (k-means tambi√©n se puede modificar para trabajar con caracter√≠sticas categ√≥ricas y ordinales).\n\n-----\n\nEscojamos un par de caracteristicas num√©ricas para el an√°lisis:"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "¬øC√≥mo se relacionan el monto financiado y los d√≠as para financiar?\n----"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Mantener solo las columnas relevantes\ncolumn_1 = 'funded_amount'\ncolumn_2 = 'repayment_term'\ndf = df[[column_1, column_2]] ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "ax = df.funded_amount.hist(grid=False);\n\nax.set(xlabel='Monto financiado', \n       ylabel='Cantidad', \n       title='Histograma del Monto Financiado');  ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "_¬øC√≥mo podemos interpretar la cantidad de pr√©stamos con diferentes montos de financiamiento?_\n\n<br>\n<br>\n<br>"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "ax = df.repayment_term.hist(grid=False);\n\nax.set(xlabel='Plazo de amortizaci√≥n', \n       ylabel='Cantidad', \n       title='Histograma del Plazo de amortizaci√≥n');  ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "_¬øC√≥mo podemos interpretar el n√∫mero de pr√©stamos para diferentes cantidades de tiempo?_\n\n<br>\n<br>\n<br>"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Filtrar datos para eliminar valores at√≠picos (outliers)\nfunded_small = df.funded_amount < 2500  # Remover grandes pr√©stamos\nrepayment_short = df.repayment_term < 60 # Remover largos periodos de amortizaci√≥n\ndf = df[funded_small & repayment_short]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "ax = df.funded_amount.hist(grid=False);\n\nax.set(xlabel='Monto Financiado', \n       ylabel='Cantidad', \n       title='Histograma de montos financiados');  ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(f\"Hay {df.shape[1]:,} columnas en el dataframe.\")\nprint(f\"Hay {df.shape[0]:,} filas en el dataframe.\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Grafica la relaci√≥n entre ambas variables\ndf.plot.scatter(x=column_1,\n                y=column_2);",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "_¬øC√≥mo podemos interpretar la relaci√≥n entre el monto financiado y el tiempo para financiar?_\n\n<br>\n<br>\n<br>"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Clustering\n======"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "----\nAjuste de nuestros datos con k-means usando scikit-learn\n----\n\nAhora podemos correr el algoritmo k-means:\n\nPodemos ver r√°pidamente la documentaci√≥n de [scikit-learn](http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html) para k-means."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Tomar la clase KMeans, inicializar y ajustar nuestros datos.\nkmeans = KMeans(n_clusters=2) # El numero de clusters deber√≠an ser 2 o 3\nkmeans.fit(df);",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Ahora que tenemos nuestros clusters, la mejor forma de entenderlo es visualizandolo."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Agregar las etiquetas de los cluster a cada punto del dataframe\ndf['kmeans_labels'] = kmeans.labels_",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# graficar k-means\nkmeans_plot = sns.lmplot(x=column_1, \n                       y=column_2, \n                       data=df, \n                       fit_reg=False,        # No ajustar una regresi√≥n lineal a los datos\n                       hue=\"kmeans_labels\",  #'hue' le da un color a cada grupo\n                       legend=True);\n\n# Grafica el promedio del cluster #1\nkmeans_plot.ax.plot(kmeans.cluster_centers_[0][0], kmeans.cluster_centers_[0][1], color='red', marker='*', markersize='8');\n\n# Grafica el promedio del cluster #2\nkmeans_plot.ax.plot(kmeans.cluster_centers_[1][0], kmeans.cluster_centers_[1][1], color='cyan', marker='*', markersize='8');\n\n# # Grafica el promedio del cluster #3 (cuando corresponde)\n# kmeans_plot.ax.plot(kmeans.cluster_centers_[2][0], kmeans.cluster_centers_[2][1], color='orange', marker='*');",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "_Por qu√© est√°n los promedios en esa posici√≥n?_\n\n<br>\n<br>\n<br>"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Eligiendo la cantidad de clusters\n-----\n\nEl algoritmo de k-means es \"ingenuo\", ya que agrupa los datos en k grupos, a√∫n si k no es el n√∫mero correcto de grupos que se deber√≠a usar.\n\nArbitrariamente, nosotros ajustamos el n√∫mero de grupos para que sean 2, pero determinar el n√∫mero apropiado de grupos (clusters, k) es la parte m√°s desafiante del procedimiento de agrupaci√≥n.\n\nNo existe una regla estricta sobre cu√°l deber√≠a ser el valor de k ya que el n√∫mero de grupos depender√° de los datos y del objetivo del an√°lisis. El n√∫mero de grupos que elijas en la partici√≥n de tus datos, influenciar√° directamente los resultados que puedas encontrar. En la mayor√≠a de las √°reas del an√°lisis de datos, es atractivo tomar un agrupamiento lo m√°s granulado posible, pero tener muchos clusters puede ser contraproducente ya que el agrupamiento no te dar√° mucha informaci√≥n.\n\n_¬øEs posible tener demasiados grupos? ¬øO muy pocos grupos?_\n\nPiensa en estos ejemplos extremos: \n\n1. Un cluster para todos tus datos\n2. Un cluster para cada punto\n\nNinguna de estas opciones te dir√° nada nuevo acerca de tus datos!\n\nM√°s bien, el m√©todo de agrupamiento es m√°s efectivo cuando las observaciones en el mismo grupo son similares entre si, adem√°s queremos que las observaciones en los diferentes grupos sean tan diferente como sea posible uno de otro. \n"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "El m√©todo Elbow para explorar el n√∫mero de clusters\n------\n\nEl m√©todo de elbow (codo) es una forma simple e intuitiva para explorar como el cambio en el n√∫mero de clusters impactar√° al \"apretamiento\" de los clusters. \n\nEl m√©todo elbow corre el agrupamiento de k-means en el mismo conjunto de datos para un rango de valores de k (digamos que k es [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]) y para cada valor de k, calcula la suma de errores cuadrados (Sum of Squared Errors, SSE) dentro de cada cluster.\n\nSSE es la distancia entre cada punto y el promedio m√°s cercano*, al cuadrado y sumada.\n\nSSE es una medida de agrupaciones internamente coherentes. Cuanto m√°s bajo es SSE, mejor (una puntuaci√≥n invertida), significa que cada grupo es muy similar a s√≠ mismo. SSE es como un puntaje de golf o frecuencia card√≠aca, m√°s bajo es mejor.\n\nA medida que k aumenta, la mejora en SSE disminuir√°. En alg√∫n momento esta falta de mejora ser√° r√°pida, creando la forma de \"codo\".\n\nSe debe elegir una cantidad de clusters tal que al agregar otro cluster no proporcione un modelado mucho mejor de los datos.\n\n<sub>*En la figura no se logra apreciar completamente porque cada eje est√° en escalas muy diferentes. T√≠picamente, los datos que se usan en k-means est√°n normalizados, por lo que los datos est√°n en la misma escala est√°ndar.</sub>\n"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "![](../images/elbow_method.png)\n\nLo que el m√©todo de elbow realiza, es lo siguiente:\n\n1. Corre el algoritmo de k-means sobre tu conjunto de datos para un rango de k.\n2. Para cada valor de k, calcula como el modelo se ajusta.\n3. Si vemos un \"codo\" en nuestra verificaci√≥n graficada, entonces eso marca un buen valor para k.\n"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Ajustemos un modelo diferente para cada valor de k\nk_values = range(1, 10)\n\n# Ajusta un modelo para cada valor de k\nk_mean_models = [KMeans(n_clusters=i) for i in k_values]\n\n# Mira como los puntajes cambian\nscores = [-k_mean_models[i].fit(df).score(df) \n              for i, model in enumerate(k_mean_models)] ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Grafiquemos los efectos de k en el clustering\nax = sns.pointplot(x=list(k_values),\n                   y=scores);\nax.set(xlabel='k', \n       ylabel='Ajuste', \n       title='M√©todo de Elbow eligiendo k');",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "_¬øC√≥mo podemos interpretar la relaci√≥n entre el cambio de k y el ajuste del clustering?_  \n_¬øPodemos ver donde la \"curva\" parece un codo en un brazo?_\n"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Visualizaci√≥n con PCA\n------\n\nUtilizamos solo dos caracter√≠sticas para el clustering, por lo que este paso de visualizaci√≥n con PCA no es realmente necesario. Sin embargo, para ilustrar el prop√≥sito de PCA, demostraremos c√≥mo se pueden resumir dos caracter√≠sticas con un componente principal.\n"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Separa las caracteristicas del dataframe\nx = df[[column_1, column_2]].values\n\n# Estandarizar (normalizar) las caracter√≠sticas\nx = StandardScaler().fit_transform(x)\n\n# Obtener el primer componente principal\npca = PCA(n_components=1)\nprincipalComponents = pca.fit_transform(x)\nprincipalDf = pd.DataFrame(data = principalComponents, columns = ['pc1'])\ndata_pca_final = df.join(principalDf)\ndata_pca_final['funded_amount_standardized'] = pd.Series(data = x[:,0], name = 'funded_amount_standardized')\ndata_pca_final['repayment_term_standardized'] = pd.Series(data = x[:,1], name = 'repayment_term_standardized')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Comprender la relaci√≥n entre el componente principal y la cantidad financiada\nplt.scatter(x=x[:,0], y=principalComponents[:,0])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Comprender la relaci√≥n entre el componente principal y el plazo de amortizaci√≥n\nplt.scatter(x=x[:,1], y=principalComponents[:,0])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "_¬øQu√© observa sobre la relaci√≥n entre el componente y sus dos caracter√≠sticas subyacentes?_"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Vuelve a correr k-means en las caracteristicas estandarizadas\ndata_pca_final = data_pca_final.loc[data_pca_final[['funded_amount_standardized', 'repayment_term_standardized']].notnull().all(axis = 1)]\nkmeans = KMeans(n_clusters=2) # N√∫mero de clusters debe ser 2 o 3\nkmeans.fit(data_pca_final[['funded_amount_standardized', 'repayment_term_standardized']])\ndata_pca_final['kmeans_labels'] = kmeans.labels_",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Grafica el componente principal respecto a los clusters\nkmeans_plot = sns.lmplot(x='pc1', \n                       y='kmeans_labels', \n                       data=data_pca_final, \n                       fit_reg=False,        # No agrega una regresion lineal al dato\n                       legend=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "_¬øQu√© notas sobre la relaci√≥n con el componente principal y la etiqueta k-means?_"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Resumen\n------\n\n- Hablamos sobre c√≥mo el aprendizaje supervisado encuentra patrones en los datos.\n- El clustering encuentra grupos dentro de un conjunto de datos.\n- El clustering usando K-means es una t√©cnica de agrupamiento popular que encuentra iterativamente los mejores grupos y el centro/medio de grupos.\n- Ajustamos k-means a los datos y evaluamos los resultados."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Estudio adicional\n-----\n\nSi quieres entender k-mean en profundidad, empieza el notebook que encontrar√°s [aqu√≠](https://jakevdp.github.io/PythonDataScienceHandbook/05.11-k-means.html)\n\nSi est√°s interesado/a en la teor√≠a detr√°s de k-means, te recomendamos este gran recurso [aqu√≠](https://www-users.cs.umn.edu/~kumar/dmbook/ch8.pdf). \n\nHay muchos otros m√©todos de agrupamiento. Otro m√©todo popular es el [Agrupamiento jerarquico](https://es.wikipedia.org/wiki/Agrupamiento_jer%C3%A1rquico)."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<br>\n<br> \n<br>\n\n----"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}