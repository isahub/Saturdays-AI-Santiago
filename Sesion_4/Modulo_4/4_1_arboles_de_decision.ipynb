{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Lab 4.1:  Arboles de Decision\n\nLos árboles de decisión se pueden usar para tareas de regresión o clasificación. Los árboles de decisión son una herramienta poderosa; sin embargo, son muy propensos a sobreajustar el conjunto de datos de capacitación y, por lo tanto, a menudo no se generalizan bien para probar conjuntos de datos. Sin embargo, son el componente básico de varios otros algoritmos de aprendizaje automático potentes y, por lo tanto, es importante conocerlos.\n\nLo que haremos en este notebook:\n-----\n\n1. Importar paquetes\n2. Cargar Datos\n3. Construir un Arbol de Decision\n4. Parametros de Sintonizacion\n5. Importancia de las Caracteristicas\n6. Tarea\n7. Material Avanzado\n\nNuestro modelo de regresion lineal anterior asume linealidad entre otros.\n\nMientras que los árboles de decisión y los algoritmos asociados ya no están restringidos a variables independientes que tienen una relación lineal y no tenemos que asegurarnos de que varios supuestos sean ciertos.\n\nPor lo tanto, podemos comenzar a incorporar otras características que podrían ser útiles.\n\nDespués de ejecutar nuestros árboles de decisión, compararemos nuestra nueva salida con nuestra salida de las regresiones lineales que ejecutamos en el cuaderno anterior.\n\nEn este cuaderno, veremos cómo podemos predecir el monto del préstamo utilizando árboles de decisión.\n\nAquí hay una introducción visual a [árboles de decisión](https://algobeans.com/2016/07/27/decision-trees-tutorial/)"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "----\nInstalar Programas Adicionales\n-----\n\nUsted necesita tener [graphviz](https://www.graphviz.org/) instalado para mostrar la estructura del arbol mas adelante.\n\nMac/Windows:\n\n```bash\n$ brew install graphviz \n```\n\nLinux:\n\n```bash\n$ sudo apt-get install graphviz\n```"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 1. Importar Paquetes"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "\"\"\"libreria para mostrar la estructura gráfica del arbol\"\"\"\nimport graphviz \n\"\"\"libreria para analisis de datos sobre estructuras flexibles\"\"\"\nimport pandas as pd\n\"\"\"libreria para uso de arreglos\"\"\"\nimport numpy as np\n\n\"\"\"funciones de estilo de comandos para funcionar con MATLAB\"\"\"\nimport matplotlib.pyplot as plt\n\"\"\"visualizacion de datos\"\"\"\nimport seaborn as sns\n%matplotlib inline\n\n\"\"\"importacion de data, modelos, etc\"\"\"\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn import tree\nfrom sklearn.metrics import mean_squared_error, r2_score",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 2. Cargar y formatear datos"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "\"\"\"Cargar datos guardado localmente\"\"\"\npath = '../data/'\nfilename = 'loans.csv'\ndf = pd.read_csv(path+filename)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "\"\"\"Cargar datos desde GitHub si usa colab\"\"\"\n#!git clone https://github.com/DeltaAnalytics/machine_learning_for_good_data\n#df = pd.read_csv(\"machine_learning_for_good_data/loans.csv\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Vamos a crear regresores para predecir el monto del préstamo y construiremos un árbol que considere muchas de las características del conjunto de datos, incluidas las que hemos diseñado nosotros mismos.\n\nAquí elegimos un subconjunto limitado de datos para realizar el análisis en pro del tiempo de entrenamiento. En la práctica, deberíamos usar más funciones. Esta es una mezcla de variables categóricas numéricas y una codificadas en caliente. "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "\"\"\"Descartar todo lo que no sea numerico\"\"\"\ndf = df.select_dtypes(exclude=['object'])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "y_column = 'loan_amount'\ny = df[y_column]\n\"\"\"Devuelve una copia del DataFrame con las columnas especificas eliminadas\"\"\"  \nX = df.drop([y_column, \"id_number\"], axis=1) # id_number no sera util",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "\"\"\"Separar la data para entrenamiento y testing\"\"\"\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 3. Construir un Arbol de Decision\nUsaremos sklearn's para la implementacion de un Arbol de Decisiones de Regresion y para aprender como usarlo, aqui estan los documentos [docs](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html#sklearn.tree.DecisionTreeRegressor.get_params), o simplemente ponga un signo de interrogacion \"?\" antes de llamar a la clase\n\nAnteceder o predeceder un \"?\" a cualquier metodo, variable, o clase mostrara la documentacion definida de ese metodo (asi se hace IPython!)"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "DecisionTreeRegressor?",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Muchos de los algoritmos de sklearn se implementan utilizando los mismos pasos estándar:\n\n- ** Paso 1: Iniciar el algoritmo ** Definir los parámetros (e hiperparámetros del algoritmo) del algoritmo. Por ejemplo, la profundidad máxima, las muestras mínimas en una hoja, etc. (consulte la documentación para obtener más información)\n\n- ** Paso 2: Entrene el algoritmo ** Entrene el algoritmo ajustándolo a los conjuntos de datos X_train e y_train.\n\n- ** Paso 3: Evaluación del algoritmo ** Evalúe el poder predictivo del algoritmo comparando los valores predictivos del monto del préstamo con los valores reales. Podemos hacer esto para el conjunto de datos de entrenamiento y prueba."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Aquí hay una función que encapsula los 3 pasos de implementación del modelo; Inicializar, entrenar, evaluar nuestro regresor del árbol de decisiones."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def train_score_regressor(sklearn_regressor, X_train, y_train, X_test, y_test, model_parameters, print_oob_score=False):\n    \"\"\"Una función auxiliar que:\n         - Entrena a un regresor en datos de entrenamiento\n         - Puntúa datos sobre entrenamiento y datos de prueba\n         - Devuelve un modelo entrenado\n    \"\"\"\n    # Paso 1: Inicializando el sklearn regressor \n    regressor = sklearn_regressor(**model_parameters)\n    \n    # Paso 2: Entrenando el algoritmo usando el set de datos de caracteristicas X_train y y_train, las caracteristicas de destino asociadas\n    regressor.fit(X_train, y_train)\n    \n    # Step 3: Cálculo de la puntuación del poder predictivo en el conjunto de datos de entrenamiento y prueba.\n    training_score = regressor.score(X_train, y_train)\n    testing_score = regressor.score(X_test, y_test)\n    \n    # Imprimir los resultados\n    \n    # print(f\"Train score: {training_score:>5.4f}\")\n    print(training_score)\n    # print(f\"Test score: {testing_score:>7.4f}\")\n    print(testing_score)\n    if print_oob_score:\n        # print(f\"OOB score: {regressor.oob_score_:>8.4f}\")\n        print(regressor.obb_score)\n    return regressor",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Con todos los algoritmos de árbol, el desafío principal es utilizar los parámetros para equilibrar el equilibrio entre sesgo y varianza. \n\nPara comenzar, verifique cómo se forma el modelo al usar los valores predeterminados."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "trained_regressor = train_score_regressor(sklearn_regressor=DecisionTreeRegressor,\n                                          X_train=X_train, \n                                          y_train=y_train, \n                                          X_test=X_test, \n                                          y_test=y_test, \n                                          model_parameters={'random_state':42})",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Nuestro módulo logró obtener un puntaje perfecto de r2 en los datos de entrenamiento, pero se desempeñó mal en los datos de la prueba. Esta es una clara indicación de que el modelo tiene ** sobreajuste a los datos de entrenamiento **.\n\nLa implementación por defecto del sklearn de DecisionTreeRegressor no impone restricciones en la profundidad del árbol, el número de muestras por hoja, etc. En consecuencia, el modelo encuentra señal en el ruido del conjunto de datos de entrenamiento, se sobreajusta y funciona mal en la prueba datos.\n\nCuando un modelo se adapta a un conjunto de datos de entrenamiento, decimos que tiene ** alta varianza **. Dado que un árbol de decisión sin restricciones modelará casi a la perfección cualquier dato de entrenamiento, variará enormemente dependiendo de los datos de entrenamiento proporcionados."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### 4. Ajuste de Parametros\nPara reducir la varianza, restringimos el modelo utilizando algunos de los parámetros proporcionados, por ejemplo:\n- Criterio (función de costo utilizada para medir la pureza de una división)\n- Profundidad máxima del árbol.\n- Muestras mínimas para cada división de nodo\n- Muestras mínimas para cada nodo terminal\n- Número máximo de nodos terminales\n\nMira hacia atras [slides](https://docs.google.com/presentation/d/1leWPbwis9GJHJcQehlhPhtKEAErUPvlTpKjnkv1aWWU/edit?usp=sharing) o utilizar esto [useful blog](https://www.analyticsvidhya.com/blog/2016/04/complete-tutorial-tree-based-modeling-scratch-in-python/#four) para una actualización de los parámetros del árbol de decisiones.\n\nInicialmente, vamos a experimentar solo con el parámetro max_depth."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Definir los parametros del modelo\n# Estamos arreglando el estado aleatorio para que los resultados sean reproducibles y consistentes.\nparameters = {\"max_depth\":6,\n              'random_state':42}\n\n# Entrenamos y evaluamos el modelo\ntrained_regressor = train_score_regressor(sklearn_regressor=DecisionTreeRegressor,\n                                          X_train=X_train, \n                                          y_train=y_train, \n                                          X_test=X_test, \n                                          y_test=y_test, \n                                          model_parameters=parameters)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Aunque el puntaje de r2 de entrenamiento ha disminuido significativamente, el puntaje de r2 de prueba aumentó. Dado que el objetivo es desarrollar un modelo que prediga con precisión los datos que nunca hemos visto, ¡esa es la métrica que nos interesa!\n\nAhora que hemos aumentado el rendimiento, echemos un vistazo a cómo se ve el Árbol de decisión."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# desde la biblioteca del árbol sklearn, cree una imagen del árbol de decisión entrenado\ndot_data = tree.export_graphviz(trained_regressor, out_file=None, \n                         feature_names=X_train.columns,  \n                         class_names=y_train.values,  \n                         filled=True, rounded=True,  \n                         special_characters=True) \n# use graphviz para reproducir la imagen\ngraph = graphviz.Source(dot_data) \ngraph",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "** IMPORTANTE**\n\nUn DecisionTreeRegressor con una profundidad máxima de solo 4 sigue siendo bastante complicado. Para desarrollar su intuición para los diversos parámetros de entrada, ajústelos manualmente hacia arriba y hacia abajo para ver los impactos.\n\nEn general, apuntamos al mayor poder predictivo en el conjunto de pruebas. Sin embargo, si tuviera que ajustar los parámetros manualmente para obtener una puntuación más alta en el conjunto de datos de prueba, nos adaptaríamos a este conjunto de datos de prueba específico y el modelo no se generalizaría bien a un conjunto de datos de prueba secundario.\n\nPara evitar esto, utilizaremos la validación k-fold. Además de la validación de k-fold, usaremos GridSearchCV de sklearn, que nos permite usar la validación de k-fold para evaluar cada permutación de valores posibles para los parámetros que proporcionamos.\n\nVer el [Advanced Material](#AdvancedCV) en la parte inferior de este notebook para obtener una descripción general rápida de estos dos métodos.\n\n** Nota ** ya que estamos entrenando un regresor una vez por cada posible permutación de valores de parámetros especificados, esta próxima celda tardará un tiempo en ejecutarse. ¡Es por eso que necesita obtener una intuición para saber qué valores probar!"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Establecer parámetros para buscar, lo que se conoce como cuadrícula de parámetros\nparameters = {'max_depth':[8,10,14], \n              'min_impurity_decrease': [.1,.01, 0.0],\n              'min_samples_split': [10, 50, 2]}\n# Inicializar el modelo\ndecision_regressor= DecisionTreeRegressor(random_state=42)\n\n# Inicializar GridSearch y entonces fit\nregressor = GridSearchCV(decision_regressor, parameters)\nregressor.fit(X_train, y_train)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# imprima lo que GridSearchCV encontró que son los mejores parámetros\nregressor.best_estimator_.get_params()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Evaluar el modelo ajustado\ntrained_regressor = train_score_regressor(sklearn_regressor=DecisionTreeRegressor,\n                                          X_train=X_train, \n                                          y_train=y_train, \n                                          X_test=X_test, \n                                          y_test=y_test, \n                                          model_parameters=regressor.best_estimator_.get_params())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "El rendimiento en los datos de prueba ha aumentado nuevamente, ¡no está mal!\n\nEl número R ^ 2 anterior es bastante revelador, pero siempre es bueno visualizar cómo se ven en un diagrama de dispersión."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# trazar un gráfico de los valores verdaderos frente a los valores predichos para los conjuntos de datos de entrenamiento y prueba\ndef plot_y_yhat_scatter(y_actual,y_predicted,train_test):\n    ax = sns.regplot(x=y_actual, y=y_predicted, fit_reg=False)\n    ax.set_xlabel('true values')\n    ax.set_ylabel('predicted values')\n    ax.set_title('Relationship between true and predicted loan amounts: '+train_test+' results')\n    pass",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "plot_y_yhat_scatter(y_train, trained_regressor.predict(X_train),train_test = \"training\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "plot_y_yhat_scatter(y_test, trained_regressor.predict(X_test),train_test = \"test\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 5. Importancia de las Caracteristicas\n\nPodemos ver qué características están impulsando las predicciones de nuestro modelo examinando la importancia de las características.\n\nRecuerde que la magnitud de la 'importancia' no es indicativa de cuán importante es la característica, ¡solo importa el orden!\n\nPor ejemplo,\n- feature A has an importance of 0.5 \n- feature B has an importance of 0.25. \n\nTodo lo que podemos ver es que la característica A explica más varianza que la característica B, ** no ** esa característica A explica el doble que la característica B."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Obtenga las características importantes de nuestro modelo entrenado final ...\nimportances = trained_regressor.feature_importances_\n\n# Encuentre los índices de las características importantes en orden descendente\nindices = np.argsort(importances)[::-1]\n\n# Trazar un gráfico de barras de las características importantes en orden descendente\nplt.figure(figsize=(12,7))\nsns.barplot(y=X_train.columns[indices],x=importances[indices]);",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "No existe una relación clara entre una sola característica y la cantidad de préstamos. La característica más importante es que el prestatario cuenta para One Acre Fund durante su período de préstamo alto; esto es muy específico para un pequeño subconjunto de datos.\n\nSin embargo, el conjunto de estas características en la decisión lleva a predicciones efectivas (R ^ 2 ~ 0.66). ¡Esto es un testimonio del poder predictivo de los árboles de decisiones!\n\nRecuerde que los árboles de decisión también se pueden usar para clasificar datos.\nPor ejemplo, algunas preguntas de clasificación interesantes que podríamos investigar son:\n\n- ¿Podemos clasificar qué préstamos vencieron y cuáles se financiaron?\n- ¿Un préstamo publicado por un hombre o una mujer?"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 6. Material avanzado: optimización del algoritmo\n<a id='AdvancedCV'></a>"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### K-folds ejemplo para encontrar parámetros óptimos"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "K-folds es un método para evaluar y ajustar un modelo en el conjunto de datos dado sin sobreajustar ni al conjunto de datos de entrenamiento ni al conjunto de datos de prueba. Encuentra el equilibrio óptimo entre sesgo y varianza en el modelo.\n\nA continuación mostramos cómo se desempeña el modelo en los conjuntos de datos de entrenamiento y prueba al tiempo que varía la profundidad máxima del árbol. "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# definir el rango de profundidad máxima\ndepth_range = np.asarray(range(2,22,2))\n\n# inicializar matrices vacías para almacenar los resultados\nscores_train = np.zeros(len(depth_range))\nscores_test = np.zeros(len(depth_range))\n\nfor i in range(len(depth_range)):\n    # Entrenar DTR con profundidad maxima dada\n    dt_regressor = DecisionTreeRegressor(max_depth=depth_range[i], random_state=42)\n    model = dt_regressor.fit(X_train, y_train)\n    # evaluar tanto en conjuntos de datos de entrenamiento como de prueba\n    scores_train[i] = model.score(X_train, y_train)\n    scores_test[i] = model.score(X_test, y_test)\n\n# trazar los resultados en el mismo gráfico\nax = sns.regplot(x=depth_range, y=scores_train, order=3, ci=None,label='train')\nsns.regplot(x=depth_range, y=scores_test,order=3, ci=None, label='test', ax=ax)\nax.legend(loc='best')\nax.set_ylabel('R2 from regression between true and predicted values')\nax.set_xlabel('Max depth of the tree')\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "A medida que aumenta la profundidad:\n- El puntaje de entrenamiento aumenta\n- Pero el puntaje de la prueba disminuye\n\nUna vez que el puntaje de la prueba comienza a disminuir, esto indica que el modelo está sobreajustado.\n\nPodríamos sentir la tentación de decir que la profundidad óptima es 8, ya que corresponde a la puntuación máxima para los datos de prueba. **Este no es siempre el caso**. El conjunto de prueba es solo un subconjunto de datos fijo aleatorio, por lo que elegir el parámetro óptimo aquí sería un ajuste excesivo para el conjunto de prueba.\n\n¡Aquí es donde entra en juego la validación cruzada de K-Folds! Este método hace lo siguiente:\n- Divide el conjunto de datos K subsistemas aleatorios iguales\n- Entrena los datos en subconjuntos K-1\n- Evalúa el rendimiento en el subconjunto Kth excluido\n- Métrica de evaluación de tiendas\n- Se repite para K veces para cada subconjunto aleatorio\n\nSi K = 5, el algoritmo se entrena 5 veces. Cada vez que muestra un quinto de los datos, entrena en los otros 4/5 y luego evalúa el rendimiento en el quinto.\n\nAquí hay un ejemplo de cómo la puntuación de validación cruzada cambia con la profundidad máxima del árbol"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Inicializar matriz vacia para almacenar resultados\nscores_cv = np.empty(len(depth_range))\nfor i in range(len(depth_range)):\n    # Inicializar modelo\n    dt_regressor = DecisionTreeRegressor(max_depth=depth_range[i], random_state=42)\n    # calcular los puntajes cruzados de val. Esto devuelve una matriz donde cada elemento corresponde al rendimiento en cada k-fold.\n    cv_scores = cross_val_score(dt_regressor, X_train, y_train,cv=5, n_jobs=-1)\n    # calcular la puntuación media de validación cruzada y guardar\n    scores_cv[i] = np.mean(cv_scores)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Trazar resultados\nax = sns.regplot(x=depth_range, y=scores_cv, ci=None, order=3);\nax.set_xlabel('Max depth of the tree');\nax.set_ylabel('Average cross validated R2');",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Una vez más, vemos que la misma tendencia general del puntaje aumenta inicialmente y luego cae. A partir de esta curva, la profundidad máxima óptima estaría entre 8 y 10."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### GridSearchCV (CV = validacion cruzada)\nArriba estábamos mirando un solo parámetro. Sin embargo, para aumentar el rendimiento debemos ajustar varios parámetros. \n\nGridSearchCV de Sklearn utiliza la validación cruzada anterior para evaluar el rendimiento de ** cada permutación posible ** de los hiperparámetros que especifique. Por esta razón, se debe tener cuidado al elegir el rango correcto de parámetros para buscar, ya que agregar un parámetro adicional puede aumentar el tiempo de búsqueda de manera exponencial.\n\nLuego devuelve un modelo inicializado con los parámetros óptimos."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "GridSearchCV?",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "parameters = {'min_impurity_decrease': [.1, 0.01, 0.],\n              'max_depth': [None, 5, 8, 10]}\n\n# inicializar modelo\ngridrf = DecisionTreeRegressor()\n\n# configurar y ajustar gridsearchCV\ngrid_rf = GridSearchCV(gridrf, parameters)\ngrid_rf.fit(X_train, y_train)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Evaluar el ajuste del modelo\ntrained_regressor = train_score_regressor(sklearn_regressor=DecisionTreeRegressor,\n                                          X_train=X_train, \n                                          y_train=y_train, \n                                          X_test=X_test, \n                                          y_test=y_test,  \n                                          model_parameters=grid_rf.best_estimator_.get_params())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Podemos verificar la variación en el puntaje promedio de validación cruzada para las diferentes permutaciones de parámetros en la búsqueda de cuadrícula y ver qué parámetros tienen el mayor impacto en el rendimiento.\n\nEn este caso particular, muestra que max_depth tiene el mayor impacto."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# obtener el puntaje promedio de validación cruzada y el estándar asociado en los pliegues K\nmeans = grid_rf.cv_results_['mean_test_score']\nstds = grid_rf.cv_results_['std_test_score']\n# imprime la media, estándar y parámetros para cada permutación\nfor mean, std, params in zip(means, stds, grid_rf.cv_results_['params']):\n    print(\"%0.3f (+/-%0.03f) for %r\"\n          % (mean, std * 2, params))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "En sus propias palabras, resuma lo que encontró sobre el comportamiento del préstamo.\n\n¿Cuáles son los factores más importantes? ¿Qué consejo le daría a alguien para maximizar sus posibilidades de tener éxito con un préstamo de KIVA?\n\n<br>\n<br> \n<br>\n\n----"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "file_extension": ".py",
      "version": "3.5.4",
      "pygments_lexer": "ipython3",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}